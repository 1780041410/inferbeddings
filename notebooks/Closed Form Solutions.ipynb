{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "nb_entities = 100\n",
    "nb_predicates = 1\n",
    "\n",
    "entity_embedding_size = 10\n",
    "predicate_embedding_size = 10\n",
    "\n",
    "\n",
    "# Instantiating entity and predicate embedding layers\n",
    "entity_embedding_layer = tf.get_variable('entities',\n",
    "                                         shape=[nb_entities + 1, entity_embedding_size],\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "predicate_embedding_layer = tf.get_variable('predicates',\n",
    "                                            shape=[nb_predicates + 1, predicate_embedding_size],\n",
    "                                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "from inferbeddings.models import base as models\n",
    "from inferbeddings.models import similarities\n",
    "\n",
    "# Instantiating the model parameters\n",
    "model_class = models.get_function('DistMult')\n",
    "similarity_function = similarities.get_function('dot')\n",
    "\n",
    "model_parameters = dict(similarity_function=similarity_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from inferbeddings.knowledgebase import Fact, KnowledgeBaseParser\n",
    "\n",
    "# Knowledge Base triples\n",
    "triples = [\n",
    "    ('a', 'p', 'b'),\n",
    "    ('c', 'p', 'd'),\n",
    "    ('a', 'q', 'b')\n",
    "]\n",
    "\n",
    "def fact(s, p, o):\n",
    "    return Fact(predicate_name=p, argument_names=[s, o])\n",
    "\n",
    "facts = [fact(s, p, o) for s, p, o in triples]\n",
    "parser = KnowledgeBaseParser(facts)\n",
    "\n",
    "from inferbeddings.parse import parse_clause\n",
    "\n",
    "# Clauses\n",
    "clause_str = 'q(x, y) :- p(x, y)'\n",
    "clauses = [parse_clause(clause_str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from inferbeddings.adversarial import Adversarial\n",
    "\n",
    "# Adversary - used for computing the adversarial loss\n",
    "adversarial = Adversarial(clauses=clauses,\n",
    "                          parser=parser,\n",
    "                          entity_embedding_layer=entity_embedding_layer,\n",
    "                          predicate_embedding_layer=predicate_embedding_layer,\n",
    "                          model_class=model_class,\n",
    "                          model_parameters=model_parameters,\n",
    "                          batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "violation_errors, violation_loss = adversarial.errors, adversarial.loss\n",
    "\n",
    "violation_finding_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "violation_training_step = violation_finding_optimizer.minimize(- violation_loss, var_list=adversarial.parameters)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
