% !TeX spellcheck = en_GB

\documentclass{sig-alternate-05-2015}

\usepackage{paralist}
\usepackage{ifxetex}

\ifxetex
\usepackage{fontspec}
\else
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\fi

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{booktabs}
\usepackage{array}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

% Macros
\newcommand{\Real}{\ensuremath{\mathbb{R}}}
\newcommand{\Natural}{\ensuremath{\mathbb{N}}}
\newcommand{\Complex}{\ensuremath{\mathbb{C}}}

\newcommand{\emb}[1]{\ensuremath{\mathbf{e}_{#1}}}
\newcommand{\remb}[1]{\ensuremath{\mathbf{r}_{#1}}}

\newcommand{\aemb}[1]{\ensuremath{\mathbf{\bar{e}}_{#1}}}
\newcommand{\Aemb}{\ensuremath{\bar{\mathbf{E}}}}

\newcommand{\rs}{\ensuremath{s}}
\newcommand{\rp}{\ensuremath{p}}
\newcommand{\relq}{\ensuremath{q}}
\newcommand{\ro}{\ensuremath{o}}

\newcommand{\pair}[2]{\ensuremath{\langle #1, #2 \rangle}}
\newcommand{\hinge}[1]{\ensuremath{\left[ #1 \right]_{+}}}

\newcommand{\trpl}[3]{\ensuremath{\langle #1, #2, #3 \rangle}}
\newcommand{\spo}{\ensuremath{\trpl{\rs}{\rp}{\ro}}}
\newcommand{\sqo}{\ensuremath{\trpl{\rs}{\relq}{\ro}}}

\newcommand{\insts}{\ensuremath{m}}

\newcommand{\kg}[1]{{\textsc{#1}}}
\newcommand{\card}[1]{{|#1|}}

\newcommand{\rel}[1]{{\textsc{#1}}}
\newcommand{\ent}[1]{{\texttt{#1}}}

\newcommand{\ie}{\textit{i}.\textit{e}.\ }
\newcommand{\eg}{\textit{e}.\textit{g}.\ }

\newcommand{\ents}{\ensuremath{\mathcal{E}}}
\newcommand{\rels}{\ensuremath{\mathcal{R}}}
\newcommand{\vars}{\ensuremath{\mathcal{V}}}
\newcommand{\tspace}{\ensuremath{\mathcal{S}}}

\newcommand{\Implies}{\ensuremath{\Rightarrow}}

\newtheorem{example}{Example}

\newcommand{\res}[1]{\textsc{#1}}
\newcommand{\mdl}[1]{{\textsc{#1}}}

\newcommand{\fscore}{\ensuremath{\phi}}
\newcommand{\params}{\ensuremath{\Theta}}
\newcommand{\Cdot}{\ensuremath{{}\cdot{}}}
\newcommand{\tdot}[3]{\ensuremath{\langle #1, #2, #3 \rangle}}

\newcommand{\ReP}[1]{\ensuremath{\text{Re}\left(#1\right)}}
\newcommand{\ImP}[1]{\ensuremath{\text{Im}\left(#1\right)}}
\newcommand{\conjt}[1]{\ensuremath{\overline{#1}}}

\newcommand{\loss}{\ensuremath{\mathcal{J}}}
\newcommand{\dloss}{\ensuremath{\loss_{D}}}
\newcommand{\aloss}{\ensuremath{\loss_{A}}}

\newcommand{\KG}{\ensuremath{\mathcal{G}}}
\newcommand{\corr}[1]{\ensuremath{\delta(#1)}}

\newcommand{\BigO}[1]{\ensuremath{\mathcal{O}(#1)}}
\newcommand{\batch}{\ensuremath{\mathcal{B}}}

\usepackage{xspace}
\newcommand{\ARI}{ARI\xspace}

\title{Adversarial Rule Injection in\\Knowledge Graph Embeddings}

\author{Pasquale Minervini$^{1}$ \and Thomas Demeester$^{2}$ \and Tim Rockt\"{a}schel$^{1}$ \and Sebastian Riedel$^{1}$ \\
$^{1}$ University College London, London, UK\\
\texttt{\{ p.minervini, t.rocktaschel, s.riedel \}@cs.ucl.ac.uk} \\
$^{2}$ Ghent University - iMinds, Ghent, Belgium\\
\texttt{tdmeeste@intec.ugent.be}
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
%
Knowledge Graph embedding models currently hold the state-of-the-art in many link prediction and knowledge base completion tasks.
%
However, a main challenge consists in efficiently incorporating background and common-sense knowledge into such models.
%
Early approaches regularize relation and entity representations by grounding first-order logic rules; however, grounding does not scale to domains with a large number of entities and relations.
%
A recent approach regularize relation representations by imposing ordering relationships over non-negative embeddings; however, it can only model a very limited set of rules.
%
In this paper we propose \emph{Adversarial Rule Injection}, an highly scalable method for incorporating general Horn clauses into distributed representations for Knowledge Graph embedding.
%
Specifically, we use a form of \emph{adversarial training} by iteratively:
%
\begin{inparaenum}[1)]
%
 \item finding \emph{counter-examples} that violate rules in the embedding space by maximizing a violation loss, and
%
 \item adjusting the model parameters so to minimize the violation loss.
%
\end{inparaenum}
%
Surprisingly we find that \ldots.
%
\end{abstract}

\input{introduction}

\input{background}

\input{adversarial}

\input{related}

\input{experiments}

\bibliographystyle{abbrv}
\bibliography{bibliography,adversarial,kr,fuzzy}

\end{document}
