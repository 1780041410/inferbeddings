% !TeX spellcheck = en_GB

\section{Adversarial Injection of\\First-Order Rules} \label{sec:injection}

%
In this section we propose \emph{Adversarial Rule Injection} (\ARI) an efficient method for incorporating first-order rules in Knowledge Graph embedding models.
%

%
An \emph{atom} is a fact (triple) that can have variables at the subject and/or object position.
%
A \emph{First-Order rule} consists of an implication between a \emph{body} and an \emph{head}, where the head is a single atom, and the body is a set of atoms.
%
Let $\vars$ be a set of universally quantified set of variables.
%
We denote a rule with head $\relq(x_{1}, x_{2})$ and body $\{ B_{1}, \ldots, B_{n} \}$ by an implication:
%
\begin{equation} \label{eq:rule}
%
 B_{1} \land B_{2} \land \ldots \land B_{m} \Implies \relq(x_{1}, x_{2})
%
\end{equation}
%
\noindent where each $x_{1}, x_{2} \in \vars$ are two variables in $\vars$, $\relq \in \rels$, and each $B_{i}$ is an atom $\rp(x_{i, 1}, x_{i, 2})$ with $\rp \in \rels$ and $x_{i, 1}, x_{i, 2} \in \vars$.
%
We abbreviate the rule in Eq.~\ref{eq:rule} by $\vec{B} \Implies \relq(x_{1}, x_{2})$.

%
An \emph{instantiation} of a rule is a copy of the rule where all variables in $\vars$ have been substituted by entities in $\ents$.
%
According to the rule in Eq.~\ref{eq:rule} is that for any instantiation of the rule, if the body holds, then the head also holds.
%

%
\begin{example}
%
Consider the sentence ``\emph{An uncle is a sibling of a parent}''.
%
It can be encoded by the following rule:
%
\begin{equation} \label{eq:rulex}
 \rel{siblingOf}(x_{1}, x_{2}) \land \rel{parentOf}(x_{2}, x_{3}) \Implies \rel{uncleOf}(x_{1}, x_{3}),
\end{equation}
%
\noindent where $\vars = \{ x_{1}, x_{2}, x_{3} \}$ is the set of variables, $\rel{uncleOf}(x_{1}, x_{3})$ is the head and $\rel{siblingOf}(x_{1}, x_{2}) \land \rel{parentOf}(x_{2}, x_{3})$ the body of the rule.
%

%
Assume $\{ \ent{Mark}, \ent{John}, \ent{Paul} \} \subseteq \ents$: according to the rule in Eq.~\ref{eq:rulex}, if $\rel{siblingOf}(\ent{Mark}, \ent{John})$ and $\rel{parentOf}(\ent{John}, \ent{Paul})$ hold, then $\rel{uncleOf}(\ent{Mark}, \ent{Paul})$ also holds.
%
\end{example}
%

%
\subsection{Grounded Loss Formulation}
%

Following \cite{DBLP:conf/emnlp/DemeesterRR16}, an implication rule in the form:
%
\begin{equation} \label{eq:simple}
%
 \rp(x_{1}, x_{2}) \Implies \relq(x_{1}, x_{2}),
%
\end{equation}
%
\noindent with $\vars = \{ x_{1}, x_{2} \}$, can be enforced by requiring that, for every pair of entities $\pair{\rs}{\ro} \in \ents \times \ents$, the triple $\spo$ is considered less likely than the triple $\sqo$, \ie:
%
\begin{equation} \label{eq:csimple}
%
 \forall \rs, \ro \in \ents : \fscore(\spo) \leq \fscore(\sqo).
%
\end{equation}
%
Note that if $\spo$ is a true fact with a high score $\fscore(\spo)$, and the fact $\sqo$ has an higher score, it must also be true, but not vice-versa.
%
We can thus enforce an implication rule by minimizing a loss term with a separate contribution for every $\pair{\rs}{\ro} \in \ents \times \ents$, adding up to the loss function in Eq.~\ref{eq:loss} if the corresponding inequality is not satisfied.
%
The implication loss for the rule in Eq.~\ref{eq:simple} can be formulated as:
%
\begin{equation} \label{eq:lsimple}
%
 \loss_{G}(\params) = \sum_{\rs \in \ents} \sum_{\ro \in \ents} \hinge{\fscore(\spo ; \params) - \fscore(\sqo ; \params)}.
%
\end{equation}
%
Note that the loss function $\loss_{G}(\params)$ in Eq.~\ref{eq:lsimple} is reaches its global minimum $0$ when parameters $\params$ match the constraints in Eq.~\ref{eq:csimple}, and it is strictly positive otherwise.
%

%
However, a limitation of implication rules in the form provided in Eq.~\ref{eq:simple} is that the body is limited to one single atom.
%
Following \cite{DBLP:conf/naacl/RocktaschelSR15}, the score for a conjunction of atoms can be computed using \emph{t-norms}~\cite{Gupta:1991:TTN:107687.107690}, for instance:
%
\begin{itemize}
%
 \item The \emph{Minimum t-norm}, also called \emph{Zadeh's t-norm}:
 \[ \fscore(\langle \rs_{1}, \rp_{1}, \ro_{1} \rangle \land \langle \rs_{2}, \rp_{2}, \ro_{2} \rangle) = \min \left\{ \fscore(\langle \rs_{1}, \rp_{1}, \ro_{1} \rangle), \fscore(\langle \rs_{2}, \rp_{2}, \ro_{2} \rangle) \right\} \]
%
 \item The \emph{Product t-norm}:
 \[ \fscore(\langle \rs_{1}, \rp_{1}, \ro_{1} \rangle \land \langle \rs_{2}, \rp_{2}, \ro_{2} \rangle) = \fscore(\langle \rs_{1}, \rp_{1}, \ro_{1} \rangle) \cdot \fscore(\langle \rs_{2}, \rp_{2}, \ro_{2} \rangle) \]
%
\end{itemize}
%

%
Let $\vars = \{ x_{1}, \ldots, x_{n} \}$, and let $x_{i} \equiv e$ denote the assignment of entity $e \in \ents$ to variable $x_{i} \in \vars$.
%
Given an implication rule in the form provided in Eq.~\ref{eq:rule}, its loss can be computed as follows:
%
\begin{equation} \label{eq:lrule}
%
 \loss_{G}(\params) = \sum_{\substack{e_{1} \in \ents \\ x_{1} \equiv e_{1}}} \ldots \sum_{\substack{e_{n} \in \ents \\ x_{n} \equiv e_{n}}} \hinge{\fscore(\vec{B} ; \params) - \fscore(\trpl{x_{1}}{\relq}{x_{2}} ; \params)}
%
\end{equation}
%

However, note that the loss in Eq.~\ref{eq:lrule} requires adding $\BigO{\card{\ents}^{n}}$ independent terms to the loss function.
%
Even for a small value of $n$, this can be unfeasible for real world Knowledge Graphs, which may contains millions of entities or more.
%

%
\subsection{Lifted Adversarial Loss Formulation}
%

%
\begin{algorithm}[t]
	\caption{Solving the minimax problem in Eq.~\ref{eq:minimax} via Stochastic Gradient Descent} \label{alg:sgd}
	\begin{algorithmic}[1]
		\Require{No. of training epochs $\tau_{a}, \tau_{d}, \tau$}
		\State{Randomly initialise model parameters $\params_{0}$}
		\For{$i \in \langle 1, \ldots, \tau \rangle$}
		\State{$\Aemb_{i} \leftarrow \textsc{FindAversarialExamples}(\params_{i - 1}, \tau_{a})$}
		\State{$\params_{i} \leftarrow \textsc{TrainModelParameters}(\Aemb_{i}, \tau_{d})$}
		\EndFor
		\State{\Return $\Theta_{\tau}$}
	\end{algorithmic}
	
	\begin{algorithmic}[1]
		\Function{FindAdversarialExamples}{$\params, \tau_{a}$}
		\State{\{Solve the loss maximization problem in Eq.~\ref{eq:oadversary}\}}
		\State{Randomly initialise $\Aemb_{0}$}
		\For{$i \in \langle 1, \ldots, \tau_{a} \rangle$}
		\State{$\emb{} \leftarrow \emb{} / \norm{\emb{}}, \; \forall \emb{} \in \Aemb$}
		\State{$g_{i} \leftarrow  \nabla_{\Aemb} \loss_{A}(\Aemb)$}
		\State{$\Aemb_{i} \leftarrow \Aemb_{i - 1} + \eta_{i} g_{i}$}
		\EndFor
		\State{\Return $\Aemb_{\tau}$}
		\EndFunction
	\end{algorithmic}
	
	\begin{algorithmic}[1]
		\Function{TrainModelParameters}{$\Aemb, \tau_{d}$}
		\State{\{Solve the loss minimization problem in Eq.~\ref{eq:odiscriminator}\}}
		\State{Randomly initialise $\params_{0}$}
		\For{$i \in \langle 1, \ldots, \tau_{d} \rangle$}
		\State{$\emb{e} \leftarrow \emb{e} / \norm{\emb{e}}, \; \forall e \in \ents$}
		\State{$\batch \leftarrow \textsc{SampleBatch}(\KG, n)$}
		
		\State{$g_{i} \leftarrow  \nabla_{\params} \sum_{ \langle t, \tilde{t} \rangle \in \batch} \hinge{\gamma - \fscore(t ; \params_{i - 1}) + \fscore(\tilde{t} ; \params_{i - 1})}$}
		\State{$\qquad \quad + \; \lambda \loss_{G}(\bar{\mathbf{E}} ; \params)$}
		\State{$\params_{i} \leftarrow \params_{i - 1} - \eta_{i} g_{i}$}
		\EndFor
		\State{\Return $\params_{\tau}$}
		\EndFunction
	\end{algorithmic}
\end{algorithm}
%

%
The problem mentioned above can be avoided if, instead of enumerating $\BigO{\card{\ents}^{n}}$ entity tuples, we iteratively find a set of \emph{adversarial counter-examples} maximizing the loss function in Eq.~\ref{eq:lrule}, and then tune the model parameters $\params$ to minimize a linear combination of the losses in Eq.~\ref{eq:loss} and Eq.~\ref{eq:lrule}.
%


%
However, finding a tuple of entities $\langle e_{1}, \ldots, e_{n} \rangle \in \ents^{n}$ maximizing the loss in Eq.~\ref{eq:lrule} is a potentially intractable combinatorial problem.
%
Efficiently finding discrete adversarial examples is an open problem in adversarial training of neural architectures~\cite{1701.00160}.
%

%
In this work, we attack this problem by instead finding a tuple of \emph{adversarial entity embeddings} $\bar{\mathbf{E}} \triangleq \langle \aemb{1}, \ldots, \aemb{n} \rangle \in \Real^{k \times n}$ maximizing the loss in Eq.~\ref{eq:lrule} using gradient-based optimization methods~\cite{Goodfellow-et-al-2016}.
%
We will refer to the loss $\loss_{G}$ evaluated on the adversarial embeddings as $\loss_{G}(\bar{\mathbf{E}} ; \params)$.
%
For the sake of clarity, in the following we denote the score of a $\spo$ triple $\fscore(\spo ; \params)$ as $\fscore(\remb{\rp}, \emb{\rs}, \emb{\ro})$.
%

%
The resulting learning procedure, which we refer to as \emph{Adversarial Rule Injection} (\ARI), can be described as a minimax game where:
%
\begin{inparaenum}[1)]
% 
 \item One agent (the \emph{adversary}) finds a set of adversarial counter-examples maximizing the loss $\loss_{G}$ in Eq.~\ref{eq:lsimple}, and
%
 \item another agent (the \emph{discriminator}) tunes the model parameters $\params$ so to simultaneously minimize the losses $\loss$ in Eq.~\ref{eq:loss} and $\loss_{G}$ in Eq.~\ref{eq:lsimple}.
%
\end{inparaenum}
%

%
The training procedure in \ARI alternates between the following two objectives:
%
\begin{description}
%
 \item[Adversary:]
 %
 \begin{equation} \label{eq:oadversary}
 %
 \begin{aligned}
 & \underset{\Aemb}{\text{maximize}}
 & & \aloss(\Aemb) \triangleq \loss_{G}(\bar{\mathbf{E}} ; \params) \\
 & \text{subject to}
 & & \displaystyle{\forall \emb{} \in \Aemb \; \norm{\emb{}} = 1,}
 \end{aligned}
 %
 \end{equation}
 %
%
 \item[Discriminator:]
 %
 \begin{equation} \label{eq:odiscriminator}
 %
 \begin{aligned}
 & \underset{\params}{\text{minimize}}
 & & \dloss(\params) \triangleq \loss(\params) + \lambda \loss_{G}(\bar{\mathbf{E}} ; \params)\\
 & \text{subject to}
 & & \displaystyle{\forall e \in \ents: \; \norm{\emb{e}} = 1,}
 \end{aligned}
 %
 \end{equation}
 %
 %
%
\end{description}
%
\noindent where $\lambda \geq 0$ is a user-specified hyper-parameter specifying the weight of the rule-based loss in the training process.
%
The learning procedure in \ARI can thus be formalized by the following minimax problem:
%
\begin{equation} \label{eq:minimax}
%
 \min_{\params} \max_{\Aemb} \dloss(\params) + \aloss(\Aemb).
%
\end{equation}
%
In Alg.~\ref{alg:sgd} we provide an algorithm for solving the minimax problem in Eq.~\ref{eq:minimax}.
%